import os
import json
import csv
import xml.etree.ElementTree as ET

# ----------------------------
# Helper Utilities
# ----------------------------
def flatten_json(obj):
    if isinstance(obj, dict):
        for k, v in obj.items():
            yield from flatten_json(v)
    elif isinstance(obj, list):
        for item in obj:
            yield from flatten_json(item)
    else:
        yield str(obj)

def matches_any(text, terms):
    return any(term.lower() in str(text).lower() for term in terms)

def get_matching_term(text, terms):
    for term in terms:
        if term.lower() in str(text).lower():
            return term
    return ""

# ----------------------------
# Parsers by Artifact Type
# ----------------------------
def parse_generic_json(file_path, terms, label):
    matches = []
    try:
        with open(file_path, encoding='utf-8') as f:
            data = json.load(f)
        values = list(flatten_json(data))
        display_name = data.get("displayName") or data.get("name") or os.path.basename(file_path)
        for val in values:
            if matches_any(val, terms):
                matched = get_matching_term(val, terms)
                matches.append({
                    "Field": matched,
                    "Type": label,
                    "Entity": "N/A",
                    "Context": f"{label}: {display_name} ‚Äî Referenced in content",
                    "File": file_path
                })
    except Exception as e:
        print(f"‚ö†Ô∏è JSON error ({label}): {file_path} ‚Äî {e}")
    return matches

def parse_code_file(file_path, terms, label):
    matches = []
    try:
        name = os.path.splitext(os.path.basename(file_path))[0]
        with open(file_path, encoding='utf-8') as f:
            for i, line in enumerate(f, 1):
                if matches_any(line, terms):
                    matched = get_matching_term(line, terms)
                    matches.append({
                        "Field": matched,
                        "Type": label,
                        "Entity": "N/A",
                        "Context": f"{label}: {name} ‚Äî Line {i}: {line.strip()[:100]}",
                        "File": file_path
                    })
    except Exception as e:
        print(f"‚ö†Ô∏è Code error ({label}): {file_path} ‚Äî {e}")
    return matches

def parse_view_fetchxml(file_path, terms):
    matches = []
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        entity = root.attrib.get("name", os.path.basename(file_path))
        view_name = os.path.splitext(os.path.basename(file_path))[0]
        for elem in root.iter():
            for attr_val in elem.attrib.values():
                if matches_any(attr_val, terms):
                    matched = get_matching_term(attr_val, terms)
                    matches.append({
                        "Field": matched,
                        "Type": "View",
                        "Entity": entity,
                        "Context": f"View: {view_name} ‚Äî Element: {elem.tag}",
                        "File": file_path
                    })
    except Exception as e:
        print(f"‚ö†Ô∏è View error: {file_path} ‚Äî {e}")
    return matches

# ----------------------------
# Master Scanner
# ----------------------------
def scan_d365_solution(root_folder, term_list):
    results = []
    for dirpath, _, files in os.walk(root_folder):
        for file in files:
            full_path = os.path.join(dirpath, file)
            low_path = full_path.lower()
            if file == "form.json":
                results += parse_generic_json(full_path, term_list, "Form")
            elif file.endswith(".fetchxml"):
                results += parse_view_fetchxml(full_path, term_list)
            elif file.endswith(".definition.json"):
                results += parse_generic_json(full_path, term_list, "Power Automate")
            elif file.endswith(".workflow.json"):
                results += parse_generic_json(full_path, term_list, "Workflow")
            elif "businessrules" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, term_list, "Business Rule")
            elif "formulas" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, term_list, "Formula")
            elif "appactions" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, term_list, "App Action")
            elif "duplicaterules" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, term_list, "Duplicate Rule")
            elif "environmentvariabledefinitions" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, term_list, "Environment Variable")
            elif file.endswith(('.js', '.ts')):
                results += parse_code_file(full_path, term_list, "Web Resource")
            elif file.endswith(".cs"):
                results += parse_code_file(full_path, term_list, "Plugin Assembly")
    return results

# ----------------------------
# Writers
# ----------------------------
def write_csv(results, filename="field_usage_report.csv"):
    keys = ["Field", "Type", "Entity", "Context", "File"]
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        writer.writerows(results)

def write_markdown(results, filename="field_usage_report.md"):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("# üìã Dynamics 365 Field/Text Usage Report\n\n")
        fields = sorted(set(r["Field"] for r in results))
        for field in fields:
            f.write(f"## üîé Term: `{field}`\n\n")
            for r in [r for r in results if r["Field"] == field]:
                f.write(f"### [{r['Type']}] {r['Entity']}\n")
                f.write(f"- üìÅ `{r['File']}`\n")
                f.write(f"- üß© **Context**: {r['Context']}\n\n")

# ----------------------------
# Configure & Run
# ----------------------------
if __name__ == "__main__":
    solution_folder = "./your_unmanaged_solution_folder"  # üîÅ Replace with path
    term_list = ["reporting expectations", "new_contactref"]  # üîç Search terms

    print(f"\nüîç Scanning for terms: {', '.join(term_list)}\n")
    results = scan_d365_solution(solution_folder, term_list)

    if results:
        print(f"‚úÖ Found {len(results)} usage(s).")
        for r in results:
            print(f"[{r['Type']}] {r['Field']} ‚Äî {r['Context']} ‚û§ {r['File']}")
        write_csv(results)
        write_markdown(results)
        print("\nüìÅ CSV saved as: field_usage_report.csv")
        print("üìù Markdown saved as: field_usage_report.md\n")
    else:
        print("‚ùå No matching content found.")
