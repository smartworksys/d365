import os
import json
import csv
import xml.etree.ElementTree as ET

# ----------------------------
# Helper Utilities
# ----------------------------
def flatten_json(obj):
    if isinstance(obj, dict):
        for v in obj.values():
            yield from flatten_json(v)
    elif isinstance(obj, list):
        for item in obj:
            yield from flatten_json(item)
    else:
        yield str(obj)

def matches_any(text, fields):
    return any(f.lower() in str(text).lower() for f in fields)

def get_matching_field(text, fields):
    for f in fields:
        if f.lower() in str(text).lower():
            return f
    return ""

# ----------------------------
# Parsers by Artifact Type
# ----------------------------
def parse_generic_json(file_path, fields, label):
    matches = []
    try:
        with open(file_path, encoding='utf-8') as f:
            data = json.load(f)
        values = list(flatten_json(data))
        display_name = data.get("displayName") or data.get("name") or os.path.basename(file_path)
        for val in values:
            if matches_any(val, fields):
                matched = get_matching_field(val, fields)
                matches.append({
                    "Field": matched,
                    "Type": label,
                    "Entity": "N/A",
                    "Context": f"{label}: {display_name} ‚Äî Referenced in structure",
                    "File": file_path
                })
    except Exception as e:
        print(f"‚ö†Ô∏è JSON error ({label}): {file_path} ‚Äî {e}")
    return matches

def parse_code_file(file_path, fields, label):
    matches = []
    try:
        resource_name = os.path.splitext(os.path.basename(file_path))[0]
        with open(file_path, encoding='utf-8') as f:
            for i, line in enumerate(f, 1):
                if matches_any(line, fields):
                    matched = get_matching_field(line, fields)
                    matches.append({
                        "Field": matched,
                        "Type": label,
                        "Entity": "N/A",
                        "Context": f"{label}: {resource_name} ‚Äî Line {i}: {line.strip()[:100]}",
                        "File": file_path
                    })
    except Exception as e:
        print(f"‚ö†Ô∏è Code error ({label}): {file_path} ‚Äî {e}")
    return matches

def parse_view_fetchxml(file_path, fields):
    matches = []
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()
        entity = root.attrib.get("name", os.path.basename(file_path))
        view_name = os.path.splitext(os.path.basename(file_path))[0]
        for attr in root.findall(".//attribute"):
            name = attr.attrib.get("name", "")
            if name.lower() in map(str.lower, fields):
                matches.append({
                    "Field": name,
                    "Type": "View",
                    "Entity": entity,
                    "Context": f"View: {view_name} ‚Äî Displayed column",
                    "File": file_path
                })
        for cond in root.findall(".//condition"):
            attr = cond.attrib.get("attribute", "")
            if attr.lower() in map(str.lower, fields):
                matches.append({
                    "Field": attr,
                    "Type": "View",
                    "Entity": entity,
                    "Context": f"View: {view_name} ‚Äî Filter condition",
                    "File": file_path
                })
    except Exception as e:
        print(f"‚ö†Ô∏è View error: {file_path} ‚Äî {e}")
    return matches

def parse_form_json(file_path, fields):
    matches = []
    try:
        with open(file_path, encoding='utf-8') as f:
            data = json.load(f)
        entity = os.path.basename(os.path.dirname(file_path))
        form_name = data.get("name") or data.get("displayName") or "Unknown Form"
        for tab in data.get("formTabs", []):
            tab_label = tab.get("label", "")
            for section in tab.get("sections", []):
                section_label = section.get("label", "")
                for control in section.get("controls", []):
                    field = control.get("dataFieldName", "")
                    if field and field.lower() in map(str.lower, fields):
                        matches.append({
                            "Field": field,
                            "Type": "Form",
                            "Entity": entity,
                            "Context": f"Form: {form_name} ‚Üí {tab_label} > {section_label}",
                            "File": file_path
                        })
    except Exception as e:
        print(f"‚ö†Ô∏è Form error: {file_path} ‚Äî {e}")
    return matches

# ----------------------------
# Master Scanner
# ----------------------------
def scan_d365_solution(root_folder, field_list):
    results = []
    for dirpath, _, files in os.walk(root_folder):
        for file in files:
            full_path = os.path.join(dirpath, file)
            low_path = full_path.lower()
            if file == "form.json":
                results += parse_form_json(full_path, field_list)
            elif file.endswith(".fetchxml"):
                results += parse_view_fetchxml(full_path, field_list)
            elif file.endswith(".definition.json"):
                results += parse_generic_json(full_path, field_list, "Power Automate")
            elif file.endswith(".workflow.json"):
                results += parse_generic_json(full_path, field_list, "Workflow")
            elif "businessrules" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, field_list, "Business Rule")
            elif "formulas" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, field_list, "Formula")
            elif "appactions" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, field_list, "App Action")
            elif "duplicaterules" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, field_list, "Duplicate Rule")
            elif "environmentvariabledefinitions" in low_path and file.endswith(".json"):
                results += parse_generic_json(full_path, field_list, "Environment Variable")
            elif file.endswith(('.js', '.ts')):
                results += parse_code_file(full_path, field_list, "Web Resource")
            elif file.endswith(".cs"):
                results += parse_code_file(full_path, field_list, "Plugin Assembly")
    return results

# ----------------------------
# Writers
# ----------------------------
def write_csv(results, filename="field_usage_report.csv"):
    keys = ["Field", "Type", "Entity", "Context", "File"]
    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        writer.writerows(results)

def write_markdown(results, filename="field_usage_report.md"):
    with open(filename, "w", encoding="utf-8") as f:
        f.write("# üìã Dynamics 365 Field Usage Report\n\n")
        fields = sorted(set(r["Field"] for r in results))
        for field in fields:
            f.write(f"## üîé Field: `{field}`\n\n")
            for r in [r for r in results if r["Field"] == field]:
                f.write(f"### [{r['Type']}] {r['Entity']}\n")
                f.write(f"- üìÅ `{r['File']}`\n")
                f.write(f"- üß© **Context**: {r['Context']}\n\n")

# ----------------------------
# Configure & Run
# ----------------------------
if __name__ == "__main__":
    solution_folder = "./your_unmanaged_solution_folder"  # üß† Replace with your unmanaged solution path
    field_list = ["new_customfieldname", "new_contactref"]  # üß† Add your target field names

    print(f"\nüîç Scanning unmanaged solution for fields: {', '.join(field_list)}\n")
    results = scan_d365_solution(solution_folder, field_list)

    if results:
        print(f"‚úÖ Found {len(results)} usage(s) across the solution.")
        for r in results:
            print(f"[{r['Type']}] {r['Field']} ‚Äî {r['Context']} ‚û§ {r['File']}")
        write_csv(results)
        write_markdown(results)
        print("\nüìÅ CSV saved as: field_usage_report.csv")
        print("üìù Markdown saved as: field_usage_report.md\n")
    else:
        print("‚ùå No field usage found.")
